{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.io import wavfile\n",
    "from cfg import Config\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from python_speech_features import mfcc\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, LSTM\n",
    "from keras.layers import Dropout, Dense, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rand_feat():\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    _min, _max = float('inf'), -float('inf')\n",
    "\n",
    "    for _ in tqdm(range(n_samples)):\n",
    "        rand_class = np.random.choice(class_dist.index, p=prob_dist)\n",
    "        f = np.random.choice(df[df['class'] == rand_class].index)\n",
    "        rate, signal = wavfile.read(df.iloc[f].c_path)\n",
    "        label = df.at[f, 'class']\n",
    "        rand_index = np.random.randint(0, signal.shape[0] - config.step)\n",
    "        sample = signal[rand_index:rand_index+config.step]\n",
    "        X_sample = mfcc(sample, rate, numcep=config.nfeat, nfilt=config.nfilt, nfft=config.nfft)\n",
    "\n",
    "        _min = min(np.amin(X_sample), _min)\n",
    "        _max = max(np.amax(X_sample), _max)\n",
    "\n",
    "        X.append(X_sample)\n",
    "        y.append(classes.index(label))\n",
    "\n",
    "    config.min = _min\n",
    "    config.max = _max\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = (X - _min) / (_max - _min)\n",
    "\n",
    "    if config.mode == 'conv':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    elif config.mode == 'time':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "    \n",
    "    y = to_categorical(y, num_classes=10)\n",
    "    config.data = (X, y)\n",
    "\n",
    "    with open(config.p_path, 'wb') as handle:\n",
    "        pickle.dump(config, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=input_shape))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_model():\n",
    "    # Shape of data for RNN is (n, time, feat)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(16, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(8, activation='relu')))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./sounds.csv')\n",
    "classes = list(np.unique(df['class']))\n",
    "class_dist = df.groupby(['class'])['length'].mean()\n",
    "n_samples = 2 * int(df.length.sum()/0.1)\n",
    "prob_dist = class_dist / class_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51230/51230 [00:38<00:00, 1336.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 9, 128)            72704     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 9, 128)            131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9, 128)            0         \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 9, 64)             8256      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 9, 32)             2080      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 9, 16)             528       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 9, 8)              136       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 72)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                730       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 216018 (843.82 KB)\n",
      "Trainable params: 216018 (843.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config = Config(mode='time')\n",
    "\n",
    "if config.mode == 'conv':\n",
    "    X, y = build_rand_feat()\n",
    "    y_flat = np.argmax(y, axis=1)\n",
    "    input_shape = (X.shape[1], X.shape[2], 1)\n",
    "    model = get_conv_model()\n",
    "\n",
    "elif config.mode == 'time':\n",
    "    X, y = build_rand_feat()\n",
    "    y_flat = np.argmax(y, axis=1)\n",
    "    input_shape = (X.shape[1], X.shape[2])\n",
    "    model = get_recurrent_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = compute_class_weight('balanced', classes=np.unique(y_flat), y=y_flat)\n",
    "class_weight = dict(zip(np.unique(y_flat), class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(config.model_path, monitor='val_acc', verbose=1, mode='max', save_best_only=True, save_weights_only=False, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1438/1441 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.8861\n",
      "Epoch 1: val_acc improved from -inf to 0.90904, saving model to models/time.model\n",
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441/1441 [==============================] - 26s 17ms/step - loss: 0.3099 - acc: 0.8862 - val_loss: 0.2348 - val_acc: 0.9090\n",
      "Epoch 2/10\n",
      "1439/1441 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9413\n",
      "Epoch 2: val_acc improved from 0.90904 to 0.94593, saving model to models/time.model\n",
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441/1441 [==============================] - 24s 16ms/step - loss: 0.1615 - acc: 0.9413 - val_loss: 0.1599 - val_acc: 0.9459\n",
      "Epoch 3/10\n",
      "1438/1441 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9596\n",
      "Epoch 3: val_acc improved from 0.94593 to 0.98126, saving model to models/time.model\n",
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441/1441 [==============================] - 24s 16ms/step - loss: 0.1102 - acc: 0.9596 - val_loss: 0.0637 - val_acc: 0.9813\n",
      "Epoch 4/10\n",
      "1438/1441 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9709\n",
      "Epoch 4: val_acc did not improve from 0.98126\n",
      "1441/1441 [==============================] - 20s 14ms/step - loss: 0.0811 - acc: 0.9709 - val_loss: 0.0614 - val_acc: 0.9795\n",
      "Epoch 5/10\n",
      "1440/1441 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9740\n",
      "Epoch 5: val_acc did not improve from 0.98126\n",
      "1441/1441 [==============================] - 20s 14ms/step - loss: 0.0726 - acc: 0.9740 - val_loss: 0.0635 - val_acc: 0.9756\n",
      "Epoch 6/10\n",
      "1438/1441 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9763\n",
      "Epoch 6: val_acc did not improve from 0.98126\n",
      "1441/1441 [==============================] - 20s 14ms/step - loss: 0.0658 - acc: 0.9763 - val_loss: 0.0555 - val_acc: 0.9813\n",
      "Epoch 7/10\n",
      "1438/1441 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9786\n",
      "Epoch 7: val_acc did not improve from 0.98126\n",
      "1441/1441 [==============================] - 20s 14ms/step - loss: 0.0590 - acc: 0.9786 - val_loss: 0.0602 - val_acc: 0.9799\n",
      "Epoch 8/10\n",
      "1438/1441 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9800\n",
      "Epoch 8: val_acc improved from 0.98126 to 0.98516, saving model to models/time.model\n",
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441/1441 [==============================] - 23s 16ms/step - loss: 0.0562 - acc: 0.9800 - val_loss: 0.0472 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "1438/1441 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9823\n",
      "Epoch 9: val_acc did not improve from 0.98516\n",
      "1441/1441 [==============================] - 23s 16ms/step - loss: 0.0501 - acc: 0.9823 - val_loss: 0.0633 - val_acc: 0.9795\n",
      "Epoch 10/10\n",
      "1437/1441 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9816\n",
      "Epoch 10: val_acc did not improve from 0.98516\n",
      "1441/1441 [==============================] - 20s 14ms/step - loss: 0.0499 - acc: 0.9817 - val_loss: 0.0620 - val_acc: 0.9776\n",
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/time.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32, shuffle=True, class_weight=class_weight, validation_split=0.1, callbacks=[checkpoint])\n",
    "model.save(config.model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
